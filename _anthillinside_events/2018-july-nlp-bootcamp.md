---
layout: workshop
title: "Bootcamp for NLP"
subtitle: Learn and implement an end-to-end deep learning models for natural language processing.
datelocation: "09:00 AM to 5:00 PM, 28-29 July 2018, ThoughtFactory, Bangalore"
city: Bangalore
start_time: 2018-07-28
end_time: 2018-07-29
description: "Learn and implement an end-to-end deep learning models for natural language processing."
boxoffice_item_collection: '26ac0e6c-4a1d-4b13-ae9c-c8bb372dd1b1'
boxoffice_item_categories:
  - name: workshop 
    title: Workshop  
    item_ids:  
      - fc3f2d1c-d106-4fb3-93b7-3c13fcfd8a9f
      - be77a858-cf15-4c9d-b268-3e2071891bcc
      - 9f9191ae-3d5f-4115-82d0-5109966eee06
      - 9249cc2b-24d2-43d4-914e-b17a5b4c4a91
   
  - name: conference 
    title: Conference  
    item_ids:  
      - 719d27f8-abc7-41c3-862d-0664d50769fa
      - a34b8f55-44e5-49b5-85c0-03eb62e17785
      - 5b1b9d9b-8f20-4530-826b-3c04c3d52d85
 
  - name: merchandise  
    title: Merchandise 
    item_ids: 
      - e50ed2ec-54eb-4e48-8783-a74c5dda31f4
 
  - name: food-court 
    title: Food Court  
    item_ids: 
      - cb36e286-fb03-4058-9380-579384b7f447

venue:
  label: ThoughtFactory, Bangalore
  address: |
    ThoughtFactory,
    Tower D, 2nd Floor,
    Diamond District, Bengaluru, Karnataka 560102
  lat: 12.95921
  lng: 77.64431
  google_maps_url: https://goo.gl/maps/eaNceNnatu62

instructors:
- name: Anuj Gupta
  byline: Director - Machine Learning, Huawei Technologies
  image_url: https://images.hasgeek.com/embed/file/a524455ee6b34301aaaa4faa31a2564a
  website:
    url: https://www.linkedin.com/in/anuj-gupta-15585792/
    label: Linkedin
  bio: |
    **Anuj** is a seasoned ML researcher; working in the area NLP, Machine Learning, Deep learning. Currently he is heading ML/DL efforts for Huawei India R&D. Prior to this he was heading ML efforts at Freshworks and Airwoot(Now acquired by Freshdesk). He dropped out of Phd in ML to work with startups. He graduated from IIIT H with specialization in theoretical comp science. He has authored a bunch of research publications and patents. He is a regular speaker at prestigious forums like PyData, Anthill, The Fifth Elephant, NVidia Dev conf, conferences in distributed algorithms. He is also co-organizer of special interest groups like DLBLR.

overview:
  left_content: |
    Think of your favorite NLP application that you wish to build - sentiment analysis, named entity recognition, machine translation, information extraction, text summarization, recommender system, to name a few. Recent advances in DL have acted as a great catalyst for pushing the boundaries of NLP

    However, feature engineering still remains a critical coponent for any NLP task. Unlike images, where directly using the intensity of pixels is a natural way to represent the image; in case of text there is no such natural representation. No matter how good is your ML/DL algorithm, it can do only so much unless there is a richer way to represent underlying text data. Thus, whatever NLP application you are building, itâ€™s imperative to find a good representation for your text data.

    In this bootcamp, we will understand key concepts, maths, and code behind the state-of-the-art NLP techniques. Various representation learning techniques have been proposed in literature, but still there is a dearth of comprehensive tutorials that provides full coverage with mathematical explanations as well as implementation details of these algorithms to a satisfactory depth.

    This bootcamp aims to bridge this gap. It aims to demystify, both - Theory (key concepts, maths) and Practice (code) that goes into building NLP models. At the end of this bootcamp participants would have gained a fundamental understanding of these approaches with an ability to implement them on datasets of their interest.


    # Target Audience
    
    * Data Science practitioners
    * Corporates and Start-ups working with NLP
    * Anyone (researcher, student, professional) working NLP  


    # Pre-requisites

    This is a very hands-on course and hence, participants should be comfortable with programming. Familiarity with python data stack is ideal. Prior knowledge of machine learning will be helpful.

    # Resources

    The material for the bootcamp is hosted on [github](https://github.com/anujgupta82/Representation-Learning-for-NLP). You can find slides for this workshop [here](https://www.slideshare.net/anujgupta5095/representation-learning-of-text-for-nlp).
  
    This is from the popular bootcamp series by the speakers on NLP. Additional materials relevant would be shared prior to the bootcamp.

  right_content: |
    # Approach
    
    This would be a two-day instructor-led hands-on bootcamp to learn and implement an end-to-end deep learning models for natural language processing.

      * Day1 will cover introduction to text representation, old ways of representing text, followed by a deep dive into embedding spaces and word vectors.
      * Day2 will cover more advanced techniques of representing text such as Paragraph2vec/doc2vector techniques and various architectures for char2vec.
    
    There will be  four  sessions of  three  hours each over two days .
    
    #### Session 1: Introduction to representation learning
            
    1. What is representation learning?
    2. Use cases in natural language processing.
    3. Old ways of representing text
      * One-hot encoding
      * Tf-idf
      * N-grams
    4. How to use pre-trained word embedding?

    #### Session 2: Word-vectors
            
    1. Introduction to word-vectors?
    2. Different techniques of generating word-vectors
      * CBOW, Skip-gram model
      * Glove model
    3. Detailed implementation of each of these models in tensorflow 
    4. Negative sampling, hierarchical softmax, tSNE
    5. Fine-tuning pretrained embeddings
    
    #### Session 3: Sentence2vec/Paragraph2vec/Doc2vec
           
    1. Extending word vectors to represent sentences/paragraphs/documents
    2. Various techniques for training doc2vec 
      * Doc2vec
        i. DM
        ii. DBOW 
      * Skip - thoughts
    3. Detailed implementation of each of these models in tensorflow
    
    #### Session 4: Char2vec

    1. Building character embeddings
    2. Tweet2vec - character embeddings from social data
    3. CNN for character vectors.
    4. fastText - character n-gram embeddings

    # Software Requirements
    
    We will be using Python data stack for this bootcamp with keras and tensorflow for the deep learning component. Additional requirement will be communicated to participants.

sponsor:
  sponsors:
  - title: "Venue Partner"
    size: "l"
    sponsors:
    - thoughtfactory

---
